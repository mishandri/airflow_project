# Описание проекта
Проект решает проблему рутинного создания новых агрегатных таблиц и гипотез-тестов в Airflow.

## Проблема
Каждый новый агрегат требует:
- Создания таблицы в БД
- Добавления задач в DAG
- Изменения кода DAG

Это приводит к большим затратам времени на однотипные действия.

## Решение
DAG генерируется динамически на основе Python-словаря (конфигурации агрегатов).

Каждый агрегат описывается структурой:
- `table_name` - имя таблицы
- `table_ddl` - SQL для создания таблицы (если не существует)
- `table_dml` - SQL для наполнения данными (с поддержкой Jinja-шаблонов и макросов Airflow)
- `need_to_export` - флаг выгрузки результата в объектное хранилище (CSV)
- `export_path` - путь выгрузки, если `need_to_export == True`

## Возможности
- Полная динамическая генерация задач в DAG
- Идемпотентность: таблицы создаются только при необходимости
- Автоматическое создание таблицы перед загрузкой данных
- Опциональная выгрузка в S3 (только где указано)
- Поддержка Jinja в SQL-запросах
- Легкое добавление новых агрегатов - достаточно дополнить конфигурацию

## Преимущества
Добавление нового агрегата = добавление записи в словарь. Никаких изменений в коде DAG.

## Структура проекта
```
config/
├── agg_config.conf                                        # конфиг, который надо закинуть в s3
dags/
├── dynamic_aggregates_final.py                            # сам даг
│
├── operators/
│   ├── operator_postgres_ensure_table_mikhail_k.py        # оператор проверки таблицы
│   ├── operator_s3_load_config_mikhail_k.py               # оператор загрузки конфига
│   └── operator_s3_export_csv_mikhail_k.py                # оператор экспорта в csv
│
└── sensors/
    └── sensor_postgres_check_empty_partition_mikhail_k.py # сенсор проверки данных в таблице в БД
```
