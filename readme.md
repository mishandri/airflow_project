# Описание проекта
Проект решает проблему рутинного создания новых агрегатных таблиц и гипотез-тестов в Airflow.

## Проблема
Каждый новый агрегат требует:
- Создания таблицы в БД
- Добавления задач в DAG
- Изменения кода DAG

Это приводит к большим затратам времени на однотипные действия.

## Решение
DAG генерируется динамически на основе Python-словаря (конфигурации агрегатов).

Каждый агрегат описывается структурой:
- name - имя таблицы
- create_sql - SQL для создания таблицы (если не существует)
- load_sql - SQL для наполнения данными (с поддержкой Jinja-шаблонов и макросов Airflow)
- export_to_s3 - флаг выгрузки результата в объектное хранилище (CSV)

## Возможности
- Полная динамическая генерация задач в DAG
- Идемпотентность: таблицы создаются только при необходимости
- Автоматическое создание таблицы перед загрузкой данных
- Опциональная выгрузка в S3 (только где указано)
- Поддержка Jinja в SQL-запросах
- Легкое добавление новых агрегатов - достаточно дополнить конфигурацию

## Преимущества
Добавление нового агрегата = добавление записи в словарь. Никаких изменений в коде DAG.

## Структура проекта
```
config/
├── agg_config.conf                                        # конфиг, который надо закинуть в s3
dags/
├── dynamic_aggregates_final.py                            # сам даг
│
├── operators/
│   ├── operator_postgres_ensure_table_mikhail_k.py        # оператор проверки таблицы
│   ├── operator_s3_load_config_mikhail_k.py               # оператор загрузки конфига
│   └── operator_s3_export_csv_mikhail_k.py                # оператор экспорта в csv
│
└── sensors/
    └── sensor_postgres_check_empty_partition_mikhail_k.py # сенсор проверки данных в таблице в БД
```
